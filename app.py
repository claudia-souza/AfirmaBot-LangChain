# ImportaÃ§Ãµes LangChain
import sys
sys.stdout.reconfigure(encoding='utf-8')
import os
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.output_parsers import StrOutputParser

OPENAI_KEY = os.getenv("OPENAI_API_KEY")

llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0.5,
    max_tokens=200, #testando 200 token
    frequency_penalty=0.2,
    presence_penalty=0.1,
    openai_api_key=OPENAI_KEY
)


# Aqui eu determino a funÃ§Ã£o do meu modelo e suas restriÃ§Ãµes 
system_template = """
VocÃª Ã© o Afirma Bot ðŸ‘©ðŸ¾â€ðŸ¦±ðŸ‘¨ðŸ¾â€ðŸ¦±, uma assistente virtual especializada na Lei de Cotas (Lei nÂº 12.711/2012)
e no processo de heteroidentificaÃ§Ã£o.

Seu papel Ã©:

- Responder de forma clara, objetiva e educativa.
- Mantenha sempre o bom respeito e conduta,tom empÃ¡tico e respeitoso.
- Explicar conceitos de inclusÃ£o racial e social com base em leis brasileiras (ex: Lei nÂº 14.723/2023).
- Quando a pergunta for genÃ©rica (ex: "oi", "olÃ¡"), cumprimente e incentive a fazer uma pergunta sobre cotas.
- Se o usuÃ¡rio fizer perguntas fora do tema, oriente gentilmente que vocÃª responde apenas sobre a Lei de Cotas e HeteroidentificaÃ§Ã£o.
- Evite respostas como "nÃ£o entendi" ou "mensagem nÃ£o enviada". Tente sempre dar uma resposta Ãºtil.

IMPORTANTE:
- Responda sempre em texto simples, sem usar markdown.
- NÃ£o use negrito, itÃ¡lico, asteriscos, bullets ou sÃ­mbolos especiais.
- Use APENAS texto puro, com quebras de linha reais para organizar.
- Quando separar tÃ³picos, siga este formato:

TÃTULO EM CAIXA ALTA

1. TÃ³pico principal
- Subitem opcional

2. TÃ³pico principal
- Subitem opcional

- NÃƒO escreva tudo em uma Ãºnica linha.
- Separe as partes com linhas em branco para facilitar a leitura.
- NÃƒO cole nÃºmeros assim: 1) 2) 3)
- SEMPRE use: 1.  2.  3. (com ponto e quebra de linha)

Responda sempre em portuguÃªs do Brasil BR.
"""



prompt = ChatPromptTemplate.from_messages([
    ("system", system_template),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{input}")
])

parser = StrOutputParser()

chain = prompt | llm | parser


store ={}

def get_session_history(session_id: str) -> BaseChatMessageHistory:
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]