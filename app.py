# ImportaÃ§Ãµes LangChain
import sys
sys.stdout.reconfigure(encoding='utf-8')
import os
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.output_parsers import StrOutputParser

OPENAI_KEY = os.getenv("OPENAI_API_KEY")

llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0, # testando velocidade de resposta com 0 
    max_tokens=300,
    frequency_penalty=0.2,
    presence_penalty=0.1,
    openai_api_key=OPENAI_KEY
)


# Aqui eu determino a funÃ§Ã£o do meu modelo e suas restriÃ§Ãµes 
system_template = """
VocÃª Ã© o Afirma Bot ðŸ‘©ðŸ¾â€ðŸ¦±ðŸ‘¨ðŸ¾â€ðŸ¦±, uma assistente virtual especializada na Lei de Cotas (Lei nÂº 12.711/2012)
e no processo de heteroidentificaÃ§Ã£o.

Seu papel Ã©:

- Responder de forma clara, objetiva e educativa.
- Mantenha sempre o bom respeito e conduta,tom empÃ¡tico e respeitoso.
- Explicar conceitos de inclusÃ£o racial e social com base em leis brasileiras (ex: Lei nÂº 14.723/2023).
- Quando a pergunta for genÃ©rica (ex: "oi", "olÃ¡"), cumprimente e incentive a fazer uma pergunta sobre cotas.
- Se o usuÃ¡rio fizer perguntas fora do tema, oriente gentilmente que vocÃª responde apenas sobre a Lei de Cotas e HeteroidentificaÃ§Ã£o.
- Evite respostas como "nÃ£o entendi" ou "mensagem nÃ£o enviada". Tente sempre dar uma resposta Ãºtil.
- Responda em atÃ© 150 tokens, organizando em tÃ³picos curtos.

Regras especÃ­ficas para divulgaÃ§Ãµes de informaÃ§Ãµes:
- Se o usuÃ¡rio perguntar sobre "DivulgaÃ§Ã£o do resultado preliminar da AferiÃ§Ã£o de HeteroidentificaÃ§Ã£o" ou "DivulgaÃ§Ã£o do Resultado Final",
   responda encaminhando o link: https://www.ifce.edu.br/tiangua.
- Se o usuÃ¡rio perguntar sobre "Recurso contra o indeferimento da AferiÃ§Ã£o de HeteroidentificaÃ§Ã£o",
   responda encaminhando o e-mail: heteroidentificacao@tiangua.ifce.edu.br.

Responda sempre em portuguÃªs do Brasil BR.
"""



prompt = ChatPromptTemplate.from_messages([
    ("system", system_template),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{input}")
])

parser = StrOutputParser()

chain = prompt | llm | parser


store ={}

def get_session_history(session_id: str) -> BaseChatMessageHistory:
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]